{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kubeflow installation guide: https://www.kubeflow.org/docs/components/pipelines/v1/installation/localcluster-deployment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import requests\n",
    "import kfp.dsl as dsl\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forbidden\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://query1.finance.yahoo.com/v7/finance/download/SAIL.NS?period1=1658311525&period2=1689847525&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "my_file = requests.get(url)\n",
    "\n",
    "data = StringIO(my_file.text)\n",
    "print(my_file.text)\n",
    "test = pd.read_csv(data)\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "test = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>74.300003</td>\n",
       "      <td>76.150002</td>\n",
       "      <td>74.150002</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>71.878113</td>\n",
       "      <td>61219545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>75.599998</td>\n",
       "      <td>72.501472</td>\n",
       "      <td>31038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>76.050003</td>\n",
       "      <td>76.300003</td>\n",
       "      <td>74.699997</td>\n",
       "      <td>75.300003</td>\n",
       "      <td>72.213768</td>\n",
       "      <td>21258642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>75.250000</td>\n",
       "      <td>76.150002</td>\n",
       "      <td>74.800003</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>72.885071</td>\n",
       "      <td>19924422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>76.599998</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>71.878113</td>\n",
       "      <td>24458733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2022-07-20  74.300003  76.150002  74.150002  74.949997  71.878113  61219545\n",
       "1  2022-07-21  75.000000  76.000000  74.400002  75.599998  72.501472  31038381\n",
       "2  2022-07-22  76.050003  76.300003  74.699997  75.300003  72.213768  21258642\n",
       "3  2022-07-25  75.250000  76.150002  74.800003  76.000000  72.885071  19924422\n",
       "4  2022-07-26  76.250000  76.599998  74.500000  74.949997  71.878113  24458733"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data():\n",
    "    import pandas as pd\n",
    "    import numpy\n",
    "    import wget\n",
    "    # data = pd.read_csv(\"data/SAIL.NS.csv\")\n",
    "    url = \"https://query1.finance.yahoo.com/v7/finance/download/SAIL.NS?period1=820454400&period2=1689811200&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "    test = wget.download(url)\n",
    "    data = pd.read_csv(test)\n",
    "    data['year'] = pd.to_datetime(data['Date']).dt.year\n",
    "    data['month'] = pd.to_datetime(data['Date']).dt.month\n",
    "    data['day'] = pd.to_datetime(data['Date']).dt.day\n",
    "    data = data.drop(['Date'], axis = 1)\n",
    "\n",
    "    for c in data.columns:\n",
    "        data[c].fillna(data[c].mean(), inplace=True)\n",
    "    data.to_csv(f'data/final_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = prepare_data()\n",
    "\n",
    "# check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    data = pd.read_csv(\"data/final_data.csv\")\n",
    "    mms = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = mms.fit_transform(data['Close'].values.reshape(-1,1))\n",
    "\n",
    "    prediction_days = 60\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(prediction_days, len(scaled_data)):\n",
    "        x_train.append(scaled_data[i - prediction_days: i, 0])\n",
    "        y_train.append(scaled_data[i, 0])\n",
    "        \n",
    "    xdata, ydata = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    train_size = 0.66\n",
    "    val_size = 0.2\n",
    "    test_size = 0.2\n",
    "\n",
    "    xtrain, ytrain = xdata[0:int(xdata.shape[0]*train_size)], ydata[0:int(ydata.shape[0]*train_size)]\n",
    "    xval, yval = xdata[xtrain.shape[0]+1:int(xtrain.shape[0] + (xdata.shape[0]-xtrain.shape[0])*0.5)], ydata[ytrain.shape[0]+1:int(ytrain.shape[0] + (ydata.shape[0]-ytrain.shape[0])*0.5)]\n",
    "    xtest, ytest = xdata[int(xtrain.shape[0]+xval.shape[0]+1):], ydata[int(ytrain.shape[0]+yval.shape[0]+1):]\n",
    "    \n",
    "    np.save(f'data/xtrain.npy',xtrain)\n",
    "    np.save(f'data/xval.npy', xval)\n",
    "    np.save(f'data/xtest.npy', xtest)\n",
    "    np.save(f'data/ytrain.npy',ytrain)\n",
    "    np.save(f'data/yval.npy', yval)\n",
    "    np.save(f'data/ytest.npy', ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_rf_regressor():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    xtrain = np.load(f'data/xtrain.npy', allow_pickle=True)\n",
    "    ytrain = np.load(f'data/ytrain.npy', allow_pickle=True)\n",
    "    rfr_final = RandomForestRegressor(n_estimators=10, max_depth=10)\n",
    "    rfr_final.fit(xtrain, ytrain)\n",
    "    rfr_optuna = RandomForestRegressor(n_estimators=11, max_depth=57)\n",
    "    rfr_optuna.fit(xtrain, ytrain)\n",
    "    \n",
    "    with open(f'data/rfr_final.pkl', 'wb') as f:\n",
    "        pickle.dump(rfr_final, f)\n",
    "        \n",
    "    with open(f'data/rfr_optuna.pkl', 'wb') as f:\n",
    "        pickle.dump(rfr_optuna, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_rf_regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test_data():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    with open(f'data/rfr_optuna.pkl', 'rb') as f:\n",
    "        rfr_optuna = pickle.load(f)\n",
    "    xtest = np.load(f'data/xtest.npy', allow_pickle=True)\n",
    "    ypred = rfr_optuna.predict(xtest)\n",
    "    np.save(f'data/ypred.npy', ypred)\n",
    "    \n",
    "    ytest = np.load(f'data/ytest.npy', allow_pickle=True)\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot(ytest, c = 'blue')\n",
    "    plt.plot(ypred, c = 'red')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_prep_data = kfp.components.create_component_from_func(\n",
    "    func = prepare_data,\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas', 'numpy', 'wget', 'matplotlib']\n",
    ")\n",
    "    \n",
    "create_setp_train_test_split = kfp.components.create_component_from_func(\n",
    "    func = train_test_split,\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn', 'matplotlib']\n",
    ")\n",
    "\n",
    "create_step_training = kfp.components.create_component_from_func(\n",
    "    func = training_rf_regressor,\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn', 'matplotlib']\n",
    ")\n",
    "\n",
    "create_step_predict = kfp.components.create_component_from_func(\n",
    "    func=prep_test_data,\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas', 'numpy', 'scikit-learn', 'matplotlib']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"sail prediction demo pipeline\",\n",
    "    description=\"testing sample\"\n",
    ")\n",
    "def sail_prediction_pipeline(data_path: str):\n",
    "    vop = dsl.VolumeOp(\n",
    "        name = \"t-vol\",\n",
    "        resource_name = \"t-vol\",\n",
    "        size = \"1Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "    )\n",
    "    \n",
    "    prepare_data_task = create_step_prep_data().add_pvolumes({data_path: vop.volume})\n",
    "    train_test_split = create_setp_train_test_split().add_pvolumes({data_path: vop.volume}).after(prepare_data_task)\n",
    "    regressor_training = create_step_training().add_pvolumes({data_path: vop.volume}).after(train_test_split)\n",
    "    predict_task = create_step_predict().add_pvolumes({data_path: vop.volume}).after(regressor_training)\n",
    "    \n",
    "    prepare_data_task.execution_options.caching_strategy.max_cache_staleness = \"POD\"\n",
    "    train_test_split.execution_options.caching_strategy.max_cache_staleness = \"POD\"\n",
    "    regressor_training.execution_options.caching_strategy.max_cache_staleness = \"POD\"\n",
    "    predict_task.execution_options.caching_strategy.max_cache_staleness = \"POD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func = sail_prediction_pipeline,\n",
    "    package_path = 'sail_prediction_pipeline.yaml'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-07\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/d7dbf759-5e7f-4c10-a4c9-341415c826a6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/b7e7a63f-f498-4b8b-9488-007f1d414880\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = '/data'\n",
    "\n",
    "import datetime\n",
    "print(datetime.datetime.now().date())\n",
    "\n",
    "pipeline_func = sail_prediction_pipeline\n",
    "experiment_name = 'sail_prediction_exp' + \"_\" + str(datetime.datetime.now().date())\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "namespace = \"kubeflow\"\n",
    "\n",
    "arguments = {\"data_path\": DATA_PATH}\n",
    "\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func,\n",
    "    '{}.zip'.format(experiment_name),\n",
    ")\n",
    "\n",
    "run_result = client.create_run_from_pipeline_func(\n",
    "    pipeline_func,\n",
    "    experiment_name = experiment_name,\n",
    "    run_name = run_name,\n",
    "    arguments = arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
